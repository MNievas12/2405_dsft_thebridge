{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_7740\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcAElEQVR4nO3df2zU9R3H8dfxo2eR9rDU9tpRsKDCJlIjg65BGErTUhMjyBZ/JuAMRCxmgL9SoyC4rA4zx3RMs0SpJuIPNn5Es5FhsSVuLQaEEXR2tKlSAi3K1rtSpDD62R+EGydF+B7Xvnvl+UgusXf37r333aVPv9716nPOOQEA0MP6WS8AALg0ESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGBigPUC39bZ2akDBw4oJSVFPp/Peh0AgEfOObW1tSk7O1v9+p37PKfXBejAgQPKycmxXgMAcJGampo0bNiwc97e6wKUkpIi6dTiqampxtsAALwKh8PKycmJ/Dw/l24L0KpVq/T888+rublZeXl5eumllzRx4sTzzp3+z26pqakECAAS2PleRumWNyG88847Wrx4sZYuXapPPvlEeXl5Ki4u1qFDh7rj4QAACahbAvTCCy9o7ty5uv/++/WDH/xAr7zyigYNGqTXXnutOx4OAJCA4h6g48ePa8eOHSosLPz/g/Trp8LCQtXU1Jx1/46ODoXD4agLAKDvi3uAvv76a508eVKZmZlR12dmZqq5ufms+5eXlysQCEQuvAMOAC4N5r+IWlZWplAoFLk0NTVZrwQA6AFxfxdcenq6+vfvr5aWlqjrW1paFAwGz7q/3++X3++P9xoAgF4u7mdASUlJGj9+vCorKyPXdXZ2qrKyUgUFBfF+OABAguqW3wNavHixZs+erR/+8IeaOHGiVq5cqfb2dt1///3d8XAAgATULQG688479dVXX2nJkiVqbm7WDTfcoE2bNp31xgQAwKXL55xz1kucKRwOKxAIKBQK8UkIAJCALvTnuPm74AAAlyYCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxADrBYDepLOz0/NMR0dHN2wSH6+//npMc+3t7Z5nPvvsM88zK1eu9Dzz5JNPep753e9+53lGkpKTkz3P/PrXv/Y8M3/+fM8zfQFnQAAAEwQIAGAi7gF65pln5PP5oi5jxoyJ98MAABJct7wGdN111+mDDz74/4MM4KUmAEC0binDgAEDFAwGu+NbAwD6iG55DWjv3r3Kzs7WyJEjde+992rfvn3nvG9HR4fC4XDUBQDQ98U9QPn5+aqoqNCmTZv08ssvq7GxUZMnT1ZbW1uX9y8vL1cgEIhccnJy4r0SAKAXinuASkpK9NOf/lTjxo1TcXGx/vznP6u1tVXvvvtul/cvKytTKBSKXJqamuK9EgCgF+r2dwcMGTJE1157rerr67u83e/3y+/3d/caAIBeptt/D+jIkSNqaGhQVlZWdz8UACCBxD1Ajz76qKqrq/XFF1/o73//u2bOnKn+/fvr7rvvjvdDAQASWNz/E9z+/ft199136/Dhw7ryyit10003qba2VldeeWW8HwoAkMDiHqC333473t8SvVQoFPI8c/LkSc8z//jHPzzP/PWvf/U8I0mtra2eZ/7whz/E9Fh9zVVXXeV55pFHHvE88+qrr3qeCQQCnmckafLkyZ5nbrnllpge61LEZ8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACZ8zjlnvcSZwuGwAoGAQqGQUlNTrde5JOzfvz+muRtuuMHzzH/+85+YHgs9q18/7/9uunnzZs8zycnJnmdikZGREdPc4MGDPc/wyf8X/nOcMyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGC9AOwNHTo0prnMzEzPM3wa9ilFRUWeZ2L5/2ndunWeZyTJ7/d7npk6dWpMj4VLF2dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJPowUSk5OjmmuoqLC88wf//hHzzMFBQWeZ2bNmuV5JlY33XST55mNGzd6nklKSvI809zc7HlGkn7729/GNAd4wRkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC55xz1kucKRwOKxAIKBQKKTU11XodxFlHR4fnmVg+hPPJJ5/0PCNJK1as8Dzz4Ycfep6ZMmWK5xkgUVzoz3HOgAAAJggQAMCE5wBt3bpVt912m7Kzs+Xz+bRhw4ao251zWrJkibKyspScnKzCwkLt3bs3XvsCAPoIzwFqb29XXl6eVq1a1eXtK1as0IsvvqhXXnlF27Zt0+WXX67i4mIdO3bsopcFAPQdnv8iaklJiUpKSrq8zTmnlStX6qmnntLtt98uSXrjjTeUmZmpDRs26K677rq4bQEAfUZcXwNqbGxUc3OzCgsLI9cFAgHl5+erpqamy5mOjg6Fw+GoCwCg74trgE7//fnMzMyo6zMzM8/5t+nLy8sVCAQil5ycnHiuBADopczfBVdWVqZQKBS5NDU1Wa8EAOgBcQ1QMBiUJLW0tERd39LSErnt2/x+v1JTU6MuAIC+L64Bys3NVTAYVGVlZeS6cDisbdu2qaCgIJ4PBQBIcJ7fBXfkyBHV19dHvm5sbNSuXbuUlpam4cOHa+HChfrFL36ha665Rrm5uXr66aeVnZ2tGTNmxHNvAECC8xyg7du36+abb458vXjxYknS7NmzVVFRoccff1zt7e2aN2+eWltbddNNN2nTpk267LLL4rc1ACDheQ7Q1KlT9V2fX+rz+bR8+XItX778ohZD3+T3+3vkca644ooeeRxJevHFFz3PTJ482fOMz+fzPAP0ZubvggMAXJoIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwvOnYQOJYOHChTHNffzxx55n1q9f73nm008/9TwzduxYzzNAb8YZEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwuecc9ZLnCkcDisQCCgUCik1NdV6HVxi/v3vf3ueGTVqlOeZtLQ0zzMzZszwPDNp0iTPM5I0c+ZMzzM+ny+mx0Lfc6E/xzkDAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM8GGkwEX6+OOPPc9Mnz7d80woFPI8E6vXXnvN88ysWbM8zwwePNjzDHo/PowUANCrESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmBlgvACS6iRMnep759NNPPc8sWrTI88zatWs9z0jSz372M88zDQ0Nnmcee+wxzzMpKSmeZ9A7cQYEADBBgAAAJjwHaOvWrbrtttuUnZ0tn8+nDRs2RN0+Z84c+Xy+qEssf/sEANC3eQ5Qe3u78vLytGrVqnPeZ/r06Tp48GDk8tZbb13UkgCAvsfzmxBKSkpUUlLynffx+/0KBoMxLwUA6Pu65TWgqqoqZWRkaPTo0Zo/f74OHz58zvt2dHQoHA5HXQAAfV/cAzR9+nS98cYbqqys1K9+9StVV1erpKREJ0+e7PL+5eXlCgQCkUtOTk68VwIA9EJx/z2gu+66K/LP119/vcaNG6dRo0apqqpK06ZNO+v+ZWVlWrx4ceTrcDhMhADgEtDtb8MeOXKk0tPTVV9f3+Xtfr9fqampURcAQN/X7QHav3+/Dh8+rKysrO5+KABAAvH8n+COHDkSdTbT2NioXbt2KS0tTWlpaVq2bJlmzZqlYDCohoYGPf7447r66qtVXFwc18UBAInNc4C2b9+um2++OfL16ddvZs+erZdfflm7d+/W66+/rtbWVmVnZ6uoqEjPPvus/H5//LYGACQ8n3POWS9xpnA4rEAgoFAoxOtBwBmOHTvmeaa2tjamxyosLPQ8E8uPkp/85CeeZ9555x3PM+hZF/pznM+CAwCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAk+DRvAWWL58yn//e9/Pc8MGOD5L8Jo9+7dnmdGjx7teQax49OwAQC9GgECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwvsnAQK4aAcOHPA8s27dOs8zNTU1nmek2D5YNBYTJkzwPHPttdd2wyawwBkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCDyMFzvDVV195nlm1apXnmdWrV3ue2b9/v+eZntS/f3/PM1dddZXnGZ/P53kGvRNnQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACT6MFL3ekSNHPM+89957MT3W8uXLPc/861//iumxerNbbrnF88xzzz3neWb8+PGeZ9B3cAYEADBBgAAAJjwFqLy8XBMmTFBKSooyMjI0Y8YM1dXVRd3n2LFjKi0t1dChQzV48GDNmjVLLS0tcV0aAJD4PAWourpapaWlqq2t1ebNm3XixAkVFRWpvb09cp9Fixbpvffe09q1a1VdXa0DBw7ojjvuiPviAIDE5ulNCJs2bYr6uqKiQhkZGdqxY4emTJmiUCikV199VWvWrIm8iLl69Wp9//vfV21trX70ox/Fb3MAQEK7qNeAQqGQJCktLU2StGPHDp04cUKFhYWR+4wZM0bDhw9XTU1Nl9+jo6ND4XA46gIA6PtiDlBnZ6cWLlyoSZMmaezYsZKk5uZmJSUlaciQIVH3zczMVHNzc5ffp7y8XIFAIHLJycmJdSUAQAKJOUClpaXas2eP3n777YtaoKysTKFQKHJpamq6qO8HAEgMMf0i6oIFC/T+++9r69atGjZsWOT6YDCo48ePq7W1NeosqKWlRcFgsMvv5ff75ff7Y1kDAJDAPJ0BOee0YMECrV+/Xlu2bFFubm7U7ePHj9fAgQNVWVkZua6urk779u1TQUFBfDYGAPQJns6ASktLtWbNGm3cuFEpKSmR13UCgYCSk5MVCAT0wAMPaPHixUpLS1NqaqoefvhhFRQU8A44AEAUTwF6+eWXJUlTp06Nun716tWaM2eOJOk3v/mN+vXrp1mzZqmjo0PFxcX6/e9/H5dlAQB9h88556yXOFM4HFYgEFAoFFJqaqr1OvgOZ/4C8oWK5U0m9913n+eZnTt3ep7p7YqKijzPLFu2LKbHmjBhgucZn88X02Oh77nQn+N8FhwAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMxPQXUdF7ffPNN55nFi5cGNNjffTRR55nPv/885geqze79dZbPc8sWbLE88wNN9zgeWbgwIGeZ4CewhkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCDyPtIV988YXnmV/+8peeZz744APPM19++aXnmd5u0KBBMc09++yznmceeughzzNJSUmeZ4C+hjMgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEH0baQ/70pz95nnn11Ve7YZP4ufHGGz3P3H333Z5nBgzw/jSdN2+e5xlJuuyyy2KaA+AdZ0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAmfc85ZL3GmcDisQCCgUCik1NRU63UAAB5d6M9xzoAAACYIEADAhKcAlZeXa8KECUpJSVFGRoZmzJihurq6qPtMnTpVPp8v6vLggw/GdWkAQOLzFKDq6mqVlpaqtrZWmzdv1okTJ1RUVKT29vao+82dO1cHDx6MXFasWBHXpQEAic/Tn5rctGlT1NcVFRXKyMjQjh07NGXKlMj1gwYNUjAYjM+GAIA+6aJeAwqFQpKktLS0qOvffPNNpaena+zYsSorK9PRo0fP+T06OjoUDoejLgCAvs/TGdCZOjs7tXDhQk2aNEljx46NXH/PPfdoxIgRys7O1u7du/XEE0+orq5O69at6/L7lJeXa9myZbGuAQBIUDH/HtD8+fP1l7/8RR999JGGDRt2zvtt2bJF06ZNU319vUaNGnXW7R0dHero6Ih8HQ6HlZOTw+8BAUCCutDfA4rpDGjBggV6//33tXXr1u+MjyTl5+dL0jkD5Pf75ff7Y1kDAJDAPAXIOaeHH35Y69evV1VVlXJzc887s2vXLklSVlZWTAsCAPomTwEqLS3VmjVrtHHjRqWkpKi5uVmSFAgElJycrIaGBq1Zs0a33nqrhg4dqt27d2vRokWaMmWKxo0b1y3/AwAAicnTa0A+n6/L61evXq05c+aoqalJ9913n/bs2aP29nbl5ORo5syZeuqppy749Rw+Cw4AElu3vAZ0vlbl5OSourray7cEAFyi+Cw4AIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJAdYLfJtzTpIUDoeNNwEAxOL0z+/TP8/PpdcFqK2tTZKUk5NjvAkA4GK0tbUpEAic83afO1+ielhnZ6cOHDiglJQU+Xy+qNvC4bBycnLU1NSk1NRUow3tcRxO4TicwnE4heNwSm84Ds45tbW1KTs7W/36nfuVnl53BtSvXz8NGzbsO++Tmpp6ST/BTuM4nMJxOIXjcArH4RTr4/BdZz6n8SYEAIAJAgQAMJFQAfL7/Vq6dKn8fr/1KqY4DqdwHE7hOJzCcTglkY5Dr3sTAgDg0pBQZ0AAgL6DAAEATBAgAIAJAgQAMJEwAVq1apWuuuoqXXbZZcrPz9fHH39svVKPe+aZZ+Tz+aIuY8aMsV6r223dulW33XabsrOz5fP5tGHDhqjbnXNasmSJsrKylJycrMLCQu3du9dm2W50vuMwZ86cs54f06dPt1m2m5SXl2vChAlKSUlRRkaGZsyYobq6uqj7HDt2TKWlpRo6dKgGDx6sWbNmqaWlxWjj7nEhx2Hq1KlnPR8efPBBo427lhABeuedd7R48WItXbpUn3zyifLy8lRcXKxDhw5Zr9bjrrvuOh08eDBy+eijj6xX6nbt7e3Ky8vTqlWrurx9xYoVevHFF/XKK69o27Ztuvzyy1VcXKxjx4718Kbd63zHQZKmT58e9fx46623enDD7lddXa3S0lLV1tZq8+bNOnHihIqKitTe3h65z6JFi/Tee+9p7dq1qq6u1oEDB3THHXcYbh1/F3IcJGnu3LlRz4cVK1YYbXwOLgFMnDjRlZaWRr4+efKky87OduXl5YZb9bylS5e6vLw86zVMSXLr16+PfN3Z2emCwaB7/vnnI9e1trY6v9/v3nrrLYMNe8a3j4Nzzs2ePdvdfvvtJvtYOXTokJPkqqurnXOn/r8fOHCgW7t2beQ+//znP50kV1NTY7Vmt/v2cXDOuR//+Mfu5z//ud1SF6DXnwEdP35cO3bsUGFhYeS6fv36qbCwUDU1NYab2di7d6+ys7M1cuRI3Xvvvdq3b5/1SqYaGxvV3Nwc9fwIBALKz8+/JJ8fVVVVysjI0OjRozV//nwdPnzYeqVuFQqFJElpaWmSpB07dujEiRNRz4cxY8Zo+PDhffr58O3jcNqbb76p9PR0jR07VmVlZTp69KjFeufU6z6M9Nu+/vprnTx5UpmZmVHXZ2Zm6vPPPzfaykZ+fr4qKio0evRoHTx4UMuWLdPkyZO1Z88epaSkWK9norm5WZK6fH6cvu1SMX36dN1xxx3Kzc1VQ0ODnnzySZWUlKimpkb9+/e3Xi/uOjs7tXDhQk2aNEljx46VdOr5kJSUpCFDhkTdty8/H7o6DpJ0zz33aMSIEcrOztbu3bv1xBNPqK6uTuvWrTPcNlqvDxD+r6SkJPLP48aNU35+vkaMGKF3331XDzzwgOFm6A3uuuuuyD9ff/31GjdunEaNGqWqqipNmzbNcLPuUVpaqj179lwSr4N+l3Mdh3nz5kX++frrr1dWVpamTZumhoYGjRo1qqfX7FKv/09w6enp6t+//1nvYmlpaVEwGDTaqncYMmSIrr32WtXX11uvYub0c4Dnx9lGjhyp9PT0Pvn8WLBggd5//319+OGHUX++JRgM6vjx42ptbY26f199PpzrOHQlPz9fknrV86HXBygpKUnjx49XZWVl5LrOzk5VVlaqoKDAcDN7R44cUUNDg7KysqxXMZObm6tgMBj1/AiHw9q2bdsl//zYv3+/Dh8+3KeeH845LViwQOvXr9eWLVuUm5sbdfv48eM1cODAqOdDXV2d9u3b16eeD+c7Dl3ZtWuXJPWu54P1uyAuxNtvv+38fr+rqKhwn332mZs3b54bMmSIa25utl6tRz3yyCOuqqrKNTY2ur/97W+usLDQpaenu0OHDlmv1q3a2trczp073c6dO50k98ILL7idO3e6L7/80jnn3HPPPeeGDBniNm7c6Hbv3u1uv/12l5ub67755hvjzePru45DW1ube/TRR11NTY1rbGx0H3zwgbvxxhvdNddc444dO2a9etzMnz/fBQIBV1VV5Q4ePBi5HD16NHKfBx980A0fPtxt2bLFbd++3RUUFLiCggLDrePvfMehvr7eLV++3G3fvt01Nja6jRs3upEjR7opU6YYbx4tIQLknHMvvfSSGz58uEtKSnITJ050tbW11iv1uDvvvNNlZWW5pKQk973vfc/deeedrr6+3nqtbvfhhx86SWddZs+e7Zw79Vbsp59+2mVmZjq/3++mTZvm6urqbJfuBt91HI4ePeqKiorclVde6QYOHOhGjBjh5s6d2+f+Ja2r//2S3OrVqyP3+eabb9xDDz3krrjiCjdo0CA3c+ZMd/DgQbulu8H5jsO+ffvclClTXFpamvP7/e7qq692jz32mAuFQraLfwt/jgEAYKLXvwYEAOibCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT/wOZOh12/MH8BAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x00000227B8E04310>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01131682,  0.05714665,  0.06924653, ...,  0.03929841,\n",
       "         0.02207857, -0.04415067],\n",
       "       [ 0.01748335,  0.00034158, -0.05891502, ..., -0.04592942,\n",
       "        -0.04526225, -0.02985714],\n",
       "       [ 0.04106613, -0.03677336, -0.04301096, ...,  0.04660722,\n",
       "         0.01173171, -0.05365624],\n",
       "       ...,\n",
       "       [ 0.06229287, -0.0685567 ,  0.03909349, ...,  0.01762585,\n",
       "         0.00196885, -0.06489025],\n",
       "       [ 0.03405543,  0.00349727,  0.04955422, ..., -0.01371665,\n",
       "        -0.00962634,  0.05403589],\n",
       "       [ 0.01194921, -0.01091875, -0.02364607, ...,  0.07317856,\n",
       "        -0.03126809, -0.01602794]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235500\n"
     ]
    }
   ],
   "source": [
    "# 1º neurona de la 1º hidden layer\n",
    "# y = a + w1*x1 + w2*x2 + .... wn*xn\n",
    "# a es el intercepto llamado bias\n",
    "# wn es cada uno de los pesos que va a ir actualizando con el backpropagation\n",
    "# n es 784\n",
    "# En la 1º hidden layer tenemos 784 pesos por cada neurona, al tener 300, tenemos un total de:\n",
    "print(784*300 + 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 784 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 10 + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "391/391 [==============================] - 4s 7ms/step - loss: 1.3318 - accuracy: 0.6727 - val_loss: 0.6394 - val_accuracy: 0.8670\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.5417 - accuracy: 0.8663 - val_loss: 0.4050 - val_accuracy: 0.8997\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.4087 - accuracy: 0.8907 - val_loss: 0.3398 - val_accuracy: 0.9081\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3552 - accuracy: 0.9018 - val_loss: 0.3065 - val_accuracy: 0.9145\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3239 - accuracy: 0.9092 - val_loss: 0.2855 - val_accuracy: 0.9198\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3009 - accuracy: 0.9151 - val_loss: 0.2687 - val_accuracy: 0.9229\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2835 - accuracy: 0.9206 - val_loss: 0.2554 - val_accuracy: 0.9266\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2687 - accuracy: 0.9241 - val_loss: 0.2445 - val_accuracy: 0.9297\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2559 - accuracy: 0.9285 - val_loss: 0.2353 - val_accuracy: 0.9323\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2445 - accuracy: 0.9310 - val_loss: 0.2254 - val_accuracy: 0.9363\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.2344 - accuracy: 0.9338 - val_loss: 0.2162 - val_accuracy: 0.9390\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2251 - accuracy: 0.9362 - val_loss: 0.2100 - val_accuracy: 0.9417\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.2164 - accuracy: 0.9390 - val_loss: 0.2030 - val_accuracy: 0.9439\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.2087 - accuracy: 0.9404 - val_loss: 0.1961 - val_accuracy: 0.9480\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.2014 - accuracy: 0.9426 - val_loss: 0.1902 - val_accuracy: 0.9489\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.1945 - accuracy: 0.9446 - val_loss: 0.1851 - val_accuracy: 0.9512\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1882 - accuracy: 0.9464 - val_loss: 0.1802 - val_accuracy: 0.9527\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1822 - accuracy: 0.9483 - val_loss: 0.1761 - val_accuracy: 0.9536\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1764 - accuracy: 0.9500 - val_loss: 0.1710 - val_accuracy: 0.9549\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1712 - accuracy: 0.9511 - val_loss: 0.1671 - val_accuracy: 0.9569\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1662 - accuracy: 0.9524 - val_loss: 0.1620 - val_accuracy: 0.9575\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1614 - accuracy: 0.9542 - val_loss: 0.1595 - val_accuracy: 0.9587\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1567 - accuracy: 0.9553 - val_loss: 0.1562 - val_accuracy: 0.9585\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1525 - accuracy: 0.9567 - val_loss: 0.1522 - val_accuracy: 0.9602\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1484 - accuracy: 0.9577 - val_loss: 0.1495 - val_accuracy: 0.9602\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1444 - accuracy: 0.9588 - val_loss: 0.1461 - val_accuracy: 0.9621\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1405 - accuracy: 0.9602 - val_loss: 0.1435 - val_accuracy: 0.9617\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1371 - accuracy: 0.9611 - val_loss: 0.1415 - val_accuracy: 0.9619\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1335 - accuracy: 0.9621 - val_loss: 0.1383 - val_accuracy: 0.9622\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1302 - accuracy: 0.9636 - val_loss: 0.1371 - val_accuracy: 0.9642\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1271 - accuracy: 0.9643 - val_loss: 0.1335 - val_accuracy: 0.9640\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1239 - accuracy: 0.9652 - val_loss: 0.1317 - val_accuracy: 0.9645\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1211 - accuracy: 0.9663 - val_loss: 0.1298 - val_accuracy: 0.9654\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1182 - accuracy: 0.9670 - val_loss: 0.1273 - val_accuracy: 0.9654\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1155 - accuracy: 0.9677 - val_loss: 0.1251 - val_accuracy: 0.9674\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1128 - accuracy: 0.9682 - val_loss: 0.1240 - val_accuracy: 0.9669\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1104 - accuracy: 0.9691 - val_loss: 0.1222 - val_accuracy: 0.9680\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.1080 - accuracy: 0.9698 - val_loss: 0.1210 - val_accuracy: 0.9684\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1055 - accuracy: 0.9704 - val_loss: 0.1191 - val_accuracy: 0.9688\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1032 - accuracy: 0.9706 - val_loss: 0.1177 - val_accuracy: 0.9695\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1009 - accuracy: 0.9719 - val_loss: 0.1156 - val_accuracy: 0.9694\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0988 - accuracy: 0.9724 - val_loss: 0.1148 - val_accuracy: 0.9700\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0967 - accuracy: 0.9731 - val_loss: 0.1138 - val_accuracy: 0.9705\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0946 - accuracy: 0.9737 - val_loss: 0.1123 - val_accuracy: 0.9702\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0927 - accuracy: 0.9747 - val_loss: 0.1111 - val_accuracy: 0.9707\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0908 - accuracy: 0.9749 - val_loss: 0.1100 - val_accuracy: 0.9699\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0890 - accuracy: 0.9753 - val_loss: 0.1080 - val_accuracy: 0.9714\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0872 - accuracy: 0.9758 - val_loss: 0.1076 - val_accuracy: 0.9715\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0854 - accuracy: 0.9763 - val_loss: 0.1063 - val_accuracy: 0.9705\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0839 - accuracy: 0.9770 - val_loss: 0.1048 - val_accuracy: 0.9718\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0831 - accuracy: 0.9769 - val_loss: 0.1058 - val_accuracy: 0.9709\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.0802 - accuracy: 0.9778 - val_loss: 0.1033 - val_accuracy: 0.9708\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0772 - accuracy: 0.9789 - val_loss: 0.1030 - val_accuracy: 0.9726\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0743 - accuracy: 0.9792 - val_loss: 0.0987 - val_accuracy: 0.9729\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0717 - accuracy: 0.9806 - val_loss: 0.0988 - val_accuracy: 0.9732\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.0694 - accuracy: 0.9808 - val_loss: 0.0971 - val_accuracy: 0.9731\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0666 - accuracy: 0.9822 - val_loss: 0.0962 - val_accuracy: 0.9724\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0646 - accuracy: 0.9826 - val_loss: 0.0955 - val_accuracy: 0.9733\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0625 - accuracy: 0.9830 - val_loss: 0.0922 - val_accuracy: 0.9746\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.0601 - accuracy: 0.9837 - val_loss: 0.0909 - val_accuracy: 0.9741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x227b5f2f910>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.3317570686340332, 0.5416649580001831, 0.4086513817310333, 0.35515254735946655, 0.3238586187362671, 0.30092132091522217, 0.2835167646408081, 0.2686994969844818, 0.2558809816837311, 0.24453428387641907, 0.23437419533729553, 0.225139781832695, 0.2164267897605896, 0.20869842171669006, 0.2014148235321045, 0.19453789293766022, 0.18819327652454376, 0.18220840394496918, 0.1764308214187622, 0.1711713671684265, 0.1662219762802124, 0.16137634217739105, 0.15674449503421783, 0.15252231061458588, 0.14837703108787537, 0.1443609893321991, 0.14052210748195648, 0.137129545211792, 0.13354671001434326, 0.1301545947790146, 0.1271134614944458, 0.12385396659374237, 0.12109655886888504, 0.1182151660323143, 0.11548880487680435, 0.11277300119400024, 0.11040236055850983, 0.10795801132917404, 0.10545067489147186, 0.10321541130542755, 0.10092833638191223, 0.09884995222091675, 0.0967436358332634, 0.0945819690823555, 0.09267554432153702, 0.09078177809715271, 0.08900626003742218, 0.08715518563985825, 0.08536449074745178, 0.08390451967716217], 'accuracy': [0.6726800203323364, 0.8662999868392944, 0.8907399773597717, 0.9017599821090698, 0.9091799855232239, 0.9150599837303162, 0.9206399917602539, 0.9241200089454651, 0.9284999966621399, 0.9310200214385986, 0.9337800145149231, 0.9362199902534485, 0.9390199780464172, 0.9403600096702576, 0.9426400065422058, 0.9446200132369995, 0.9464200139045715, 0.9483399987220764, 0.949999988079071, 0.9510999917984009, 0.9524400234222412, 0.954200029373169, 0.9552599787712097, 0.9567000269889832, 0.9577000141143799, 0.9587799906730652, 0.9602199792861938, 0.961139976978302, 0.962119996547699, 0.9635599851608276, 0.9642999768257141, 0.9652000069618225, 0.9663000106811523, 0.9670400023460388, 0.9677199721336365, 0.9682400226593018, 0.9691399931907654, 0.9698399901390076, 0.9703599810600281, 0.9706199765205383, 0.9718599915504456, 0.9724400043487549, 0.9730600118637085, 0.9736999869346619, 0.9747400283813477, 0.9749000072479248, 0.9753000140190125, 0.9757800102233887, 0.9762799739837646, 0.9769799709320068], 'val_loss': [0.6393529772758484, 0.40498560667037964, 0.3397802412509918, 0.3065146803855896, 0.2854853868484497, 0.2687312662601471, 0.2553967535495758, 0.24454542994499207, 0.23527231812477112, 0.22543124854564667, 0.21618354320526123, 0.20996123552322388, 0.20301534235477448, 0.19610679149627686, 0.1901886910200119, 0.18511560559272766, 0.1802460104227066, 0.17605605721473694, 0.17098446190357208, 0.1671144962310791, 0.16196513175964355, 0.1594940721988678, 0.1562090665102005, 0.1521790623664856, 0.14953650534152985, 0.14609409868717194, 0.14351947605609894, 0.14152351021766663, 0.1382519155740738, 0.1371140480041504, 0.13349854946136475, 0.13166920840740204, 0.1297508180141449, 0.12727747857570648, 0.12508966028690338, 0.12397052347660065, 0.12223034352064133, 0.12098830938339233, 0.11913582682609558, 0.11766423285007477, 0.11559519171714783, 0.11480540782213211, 0.11383046954870224, 0.11231455951929092, 0.1110578253865242, 0.11001165956258774, 0.10801006108522415, 0.10755672305822372, 0.10633060336112976, 0.10478617995977402], 'val_accuracy': [0.8669999837875366, 0.8996999859809875, 0.9081000089645386, 0.9144999980926514, 0.9197999835014343, 0.9229000210762024, 0.9265999794006348, 0.9297000169754028, 0.9322999715805054, 0.9362999796867371, 0.9390000104904175, 0.9416999816894531, 0.9438999891281128, 0.9480000138282776, 0.9488999843597412, 0.951200008392334, 0.9527000188827515, 0.9535999894142151, 0.9549000263214111, 0.9569000005722046, 0.9574999809265137, 0.9587000012397766, 0.9585000276565552, 0.9602000117301941, 0.9602000117301941, 0.9621000289916992, 0.9617000222206116, 0.961899995803833, 0.9621999859809875, 0.9642000198364258, 0.9639999866485596, 0.9645000100135803, 0.965399980545044, 0.965399980545044, 0.9674000144004822, 0.9668999910354614, 0.9679999947547913, 0.9684000015258789, 0.9688000082969666, 0.9695000052452087, 0.9693999886512756, 0.9700000286102295, 0.9704999923706055, 0.9702000021934509, 0.9707000255584717, 0.9699000120162964, 0.9714000225067139, 0.9714999794960022, 0.9704999923706055, 0.9718000292778015]}\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3317570686340332,\n",
       "  0.5416649580001831,\n",
       "  0.4086513817310333,\n",
       "  0.35515254735946655,\n",
       "  0.3238586187362671,\n",
       "  0.30092132091522217,\n",
       "  0.2835167646408081,\n",
       "  0.2686994969844818,\n",
       "  0.2558809816837311,\n",
       "  0.24453428387641907,\n",
       "  0.23437419533729553,\n",
       "  0.225139781832695,\n",
       "  0.2164267897605896,\n",
       "  0.20869842171669006,\n",
       "  0.2014148235321045,\n",
       "  0.19453789293766022,\n",
       "  0.18819327652454376,\n",
       "  0.18220840394496918,\n",
       "  0.1764308214187622,\n",
       "  0.1711713671684265,\n",
       "  0.1662219762802124,\n",
       "  0.16137634217739105,\n",
       "  0.15674449503421783,\n",
       "  0.15252231061458588,\n",
       "  0.14837703108787537,\n",
       "  0.1443609893321991,\n",
       "  0.14052210748195648,\n",
       "  0.137129545211792,\n",
       "  0.13354671001434326,\n",
       "  0.1301545947790146,\n",
       "  0.1271134614944458,\n",
       "  0.12385396659374237,\n",
       "  0.12109655886888504,\n",
       "  0.1182151660323143,\n",
       "  0.11548880487680435,\n",
       "  0.11277300119400024,\n",
       "  0.11040236055850983,\n",
       "  0.10795801132917404,\n",
       "  0.10545067489147186,\n",
       "  0.10321541130542755,\n",
       "  0.10092833638191223,\n",
       "  0.09884995222091675,\n",
       "  0.0967436358332634,\n",
       "  0.0945819690823555,\n",
       "  0.09267554432153702,\n",
       "  0.09078177809715271,\n",
       "  0.08900626003742218,\n",
       "  0.08715518563985825,\n",
       "  0.08536449074745178,\n",
       "  0.08390451967716217],\n",
       " 'accuracy': [0.6726800203323364,\n",
       "  0.8662999868392944,\n",
       "  0.8907399773597717,\n",
       "  0.9017599821090698,\n",
       "  0.9091799855232239,\n",
       "  0.9150599837303162,\n",
       "  0.9206399917602539,\n",
       "  0.9241200089454651,\n",
       "  0.9284999966621399,\n",
       "  0.9310200214385986,\n",
       "  0.9337800145149231,\n",
       "  0.9362199902534485,\n",
       "  0.9390199780464172,\n",
       "  0.9403600096702576,\n",
       "  0.9426400065422058,\n",
       "  0.9446200132369995,\n",
       "  0.9464200139045715,\n",
       "  0.9483399987220764,\n",
       "  0.949999988079071,\n",
       "  0.9510999917984009,\n",
       "  0.9524400234222412,\n",
       "  0.954200029373169,\n",
       "  0.9552599787712097,\n",
       "  0.9567000269889832,\n",
       "  0.9577000141143799,\n",
       "  0.9587799906730652,\n",
       "  0.9602199792861938,\n",
       "  0.961139976978302,\n",
       "  0.962119996547699,\n",
       "  0.9635599851608276,\n",
       "  0.9642999768257141,\n",
       "  0.9652000069618225,\n",
       "  0.9663000106811523,\n",
       "  0.9670400023460388,\n",
       "  0.9677199721336365,\n",
       "  0.9682400226593018,\n",
       "  0.9691399931907654,\n",
       "  0.9698399901390076,\n",
       "  0.9703599810600281,\n",
       "  0.9706199765205383,\n",
       "  0.9718599915504456,\n",
       "  0.9724400043487549,\n",
       "  0.9730600118637085,\n",
       "  0.9736999869346619,\n",
       "  0.9747400283813477,\n",
       "  0.9749000072479248,\n",
       "  0.9753000140190125,\n",
       "  0.9757800102233887,\n",
       "  0.9762799739837646,\n",
       "  0.9769799709320068],\n",
       " 'val_loss': [0.6393529772758484,\n",
       "  0.40498560667037964,\n",
       "  0.3397802412509918,\n",
       "  0.3065146803855896,\n",
       "  0.2854853868484497,\n",
       "  0.2687312662601471,\n",
       "  0.2553967535495758,\n",
       "  0.24454542994499207,\n",
       "  0.23527231812477112,\n",
       "  0.22543124854564667,\n",
       "  0.21618354320526123,\n",
       "  0.20996123552322388,\n",
       "  0.20301534235477448,\n",
       "  0.19610679149627686,\n",
       "  0.1901886910200119,\n",
       "  0.18511560559272766,\n",
       "  0.1802460104227066,\n",
       "  0.17605605721473694,\n",
       "  0.17098446190357208,\n",
       "  0.1671144962310791,\n",
       "  0.16196513175964355,\n",
       "  0.1594940721988678,\n",
       "  0.1562090665102005,\n",
       "  0.1521790623664856,\n",
       "  0.14953650534152985,\n",
       "  0.14609409868717194,\n",
       "  0.14351947605609894,\n",
       "  0.14152351021766663,\n",
       "  0.1382519155740738,\n",
       "  0.1371140480041504,\n",
       "  0.13349854946136475,\n",
       "  0.13166920840740204,\n",
       "  0.1297508180141449,\n",
       "  0.12727747857570648,\n",
       "  0.12508966028690338,\n",
       "  0.12397052347660065,\n",
       "  0.12223034352064133,\n",
       "  0.12098830938339233,\n",
       "  0.11913582682609558,\n",
       "  0.11766423285007477,\n",
       "  0.11559519171714783,\n",
       "  0.11480540782213211,\n",
       "  0.11383046954870224,\n",
       "  0.11231455951929092,\n",
       "  0.1110578253865242,\n",
       "  0.11001165956258774,\n",
       "  0.10801006108522415,\n",
       "  0.10755672305822372,\n",
       "  0.10633060336112976,\n",
       "  0.10478617995977402],\n",
       " 'val_accuracy': [0.8669999837875366,\n",
       "  0.8996999859809875,\n",
       "  0.9081000089645386,\n",
       "  0.9144999980926514,\n",
       "  0.9197999835014343,\n",
       "  0.9229000210762024,\n",
       "  0.9265999794006348,\n",
       "  0.9297000169754028,\n",
       "  0.9322999715805054,\n",
       "  0.9362999796867371,\n",
       "  0.9390000104904175,\n",
       "  0.9416999816894531,\n",
       "  0.9438999891281128,\n",
       "  0.9480000138282776,\n",
       "  0.9488999843597412,\n",
       "  0.951200008392334,\n",
       "  0.9527000188827515,\n",
       "  0.9535999894142151,\n",
       "  0.9549000263214111,\n",
       "  0.9569000005722046,\n",
       "  0.9574999809265137,\n",
       "  0.9587000012397766,\n",
       "  0.9585000276565552,\n",
       "  0.9602000117301941,\n",
       "  0.9602000117301941,\n",
       "  0.9621000289916992,\n",
       "  0.9617000222206116,\n",
       "  0.961899995803833,\n",
       "  0.9621999859809875,\n",
       "  0.9642000198364258,\n",
       "  0.9639999866485596,\n",
       "  0.9645000100135803,\n",
       "  0.965399980545044,\n",
       "  0.965399980545044,\n",
       "  0.9674000144004822,\n",
       "  0.9668999910354614,\n",
       "  0.9679999947547913,\n",
       "  0.9684000015258789,\n",
       "  0.9688000082969666,\n",
       "  0.9695000052452087,\n",
       "  0.9693999886512756,\n",
       "  0.9700000286102295,\n",
       "  0.9704999923706055,\n",
       "  0.9702000021934509,\n",
       "  0.9707000255584717,\n",
       "  0.9699000120162964,\n",
       "  0.9714000225067139,\n",
       "  0.9714999794960022,\n",
       "  0.9704999923706055,\n",
       "  0.9718000292778015]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.331757</td>\n",
       "      <td>0.67268</td>\n",
       "      <td>0.639353</td>\n",
       "      <td>0.8670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.541665</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.404986</td>\n",
       "      <td>0.8997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.408651</td>\n",
       "      <td>0.89074</td>\n",
       "      <td>0.339780</td>\n",
       "      <td>0.9081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.355153</td>\n",
       "      <td>0.90176</td>\n",
       "      <td>0.306515</td>\n",
       "      <td>0.9145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.323859</td>\n",
       "      <td>0.90918</td>\n",
       "      <td>0.285485</td>\n",
       "      <td>0.9198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.300921</td>\n",
       "      <td>0.91506</td>\n",
       "      <td>0.268731</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.283517</td>\n",
       "      <td>0.92064</td>\n",
       "      <td>0.255397</td>\n",
       "      <td>0.9266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.268699</td>\n",
       "      <td>0.92412</td>\n",
       "      <td>0.244545</td>\n",
       "      <td>0.9297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.255881</td>\n",
       "      <td>0.92850</td>\n",
       "      <td>0.235272</td>\n",
       "      <td>0.9323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.244534</td>\n",
       "      <td>0.93102</td>\n",
       "      <td>0.225431</td>\n",
       "      <td>0.9363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.234374</td>\n",
       "      <td>0.93378</td>\n",
       "      <td>0.216184</td>\n",
       "      <td>0.9390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.225140</td>\n",
       "      <td>0.93622</td>\n",
       "      <td>0.209961</td>\n",
       "      <td>0.9417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.216427</td>\n",
       "      <td>0.93902</td>\n",
       "      <td>0.203015</td>\n",
       "      <td>0.9439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.208698</td>\n",
       "      <td>0.94036</td>\n",
       "      <td>0.196107</td>\n",
       "      <td>0.9480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.201415</td>\n",
       "      <td>0.94264</td>\n",
       "      <td>0.190189</td>\n",
       "      <td>0.9489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.194538</td>\n",
       "      <td>0.94462</td>\n",
       "      <td>0.185116</td>\n",
       "      <td>0.9512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.188193</td>\n",
       "      <td>0.94642</td>\n",
       "      <td>0.180246</td>\n",
       "      <td>0.9527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.182208</td>\n",
       "      <td>0.94834</td>\n",
       "      <td>0.176056</td>\n",
       "      <td>0.9536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.176431</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.170984</td>\n",
       "      <td>0.9549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.95110</td>\n",
       "      <td>0.167114</td>\n",
       "      <td>0.9569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.166222</td>\n",
       "      <td>0.95244</td>\n",
       "      <td>0.161965</td>\n",
       "      <td>0.9575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.161376</td>\n",
       "      <td>0.95420</td>\n",
       "      <td>0.159494</td>\n",
       "      <td>0.9587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.156744</td>\n",
       "      <td>0.95526</td>\n",
       "      <td>0.156209</td>\n",
       "      <td>0.9585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.152522</td>\n",
       "      <td>0.95670</td>\n",
       "      <td>0.152179</td>\n",
       "      <td>0.9602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.148377</td>\n",
       "      <td>0.95770</td>\n",
       "      <td>0.149537</td>\n",
       "      <td>0.9602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.144361</td>\n",
       "      <td>0.95878</td>\n",
       "      <td>0.146094</td>\n",
       "      <td>0.9621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.140522</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>0.143519</td>\n",
       "      <td>0.9617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.137130</td>\n",
       "      <td>0.96114</td>\n",
       "      <td>0.141524</td>\n",
       "      <td>0.9619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.133547</td>\n",
       "      <td>0.96212</td>\n",
       "      <td>0.138252</td>\n",
       "      <td>0.9622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.130155</td>\n",
       "      <td>0.96356</td>\n",
       "      <td>0.137114</td>\n",
       "      <td>0.9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.127113</td>\n",
       "      <td>0.96430</td>\n",
       "      <td>0.133499</td>\n",
       "      <td>0.9640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.123854</td>\n",
       "      <td>0.96520</td>\n",
       "      <td>0.131669</td>\n",
       "      <td>0.9645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.121097</td>\n",
       "      <td>0.96630</td>\n",
       "      <td>0.129751</td>\n",
       "      <td>0.9654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.118215</td>\n",
       "      <td>0.96704</td>\n",
       "      <td>0.127277</td>\n",
       "      <td>0.9654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.115489</td>\n",
       "      <td>0.96772</td>\n",
       "      <td>0.125090</td>\n",
       "      <td>0.9674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.112773</td>\n",
       "      <td>0.96824</td>\n",
       "      <td>0.123971</td>\n",
       "      <td>0.9669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.110402</td>\n",
       "      <td>0.96914</td>\n",
       "      <td>0.122230</td>\n",
       "      <td>0.9680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.96984</td>\n",
       "      <td>0.120988</td>\n",
       "      <td>0.9684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.105451</td>\n",
       "      <td>0.97036</td>\n",
       "      <td>0.119136</td>\n",
       "      <td>0.9688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.103215</td>\n",
       "      <td>0.97062</td>\n",
       "      <td>0.117664</td>\n",
       "      <td>0.9695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.100928</td>\n",
       "      <td>0.97186</td>\n",
       "      <td>0.115595</td>\n",
       "      <td>0.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.098850</td>\n",
       "      <td>0.97244</td>\n",
       "      <td>0.114805</td>\n",
       "      <td>0.9700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.096744</td>\n",
       "      <td>0.97306</td>\n",
       "      <td>0.113830</td>\n",
       "      <td>0.9705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.094582</td>\n",
       "      <td>0.97370</td>\n",
       "      <td>0.112315</td>\n",
       "      <td>0.9702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.092676</td>\n",
       "      <td>0.97474</td>\n",
       "      <td>0.111058</td>\n",
       "      <td>0.9707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.090782</td>\n",
       "      <td>0.97490</td>\n",
       "      <td>0.110012</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.089006</td>\n",
       "      <td>0.97530</td>\n",
       "      <td>0.108010</td>\n",
       "      <td>0.9714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.087155</td>\n",
       "      <td>0.97578</td>\n",
       "      <td>0.107557</td>\n",
       "      <td>0.9715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.085364</td>\n",
       "      <td>0.97628</td>\n",
       "      <td>0.106331</td>\n",
       "      <td>0.9705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.083905</td>\n",
       "      <td>0.97698</td>\n",
       "      <td>0.104786</td>\n",
       "      <td>0.9718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.331757   0.67268  0.639353        0.8670\n",
       "1   0.541665   0.86630  0.404986        0.8997\n",
       "2   0.408651   0.89074  0.339780        0.9081\n",
       "3   0.355153   0.90176  0.306515        0.9145\n",
       "4   0.323859   0.90918  0.285485        0.9198\n",
       "5   0.300921   0.91506  0.268731        0.9229\n",
       "6   0.283517   0.92064  0.255397        0.9266\n",
       "7   0.268699   0.92412  0.244545        0.9297\n",
       "8   0.255881   0.92850  0.235272        0.9323\n",
       "9   0.244534   0.93102  0.225431        0.9363\n",
       "10  0.234374   0.93378  0.216184        0.9390\n",
       "11  0.225140   0.93622  0.209961        0.9417\n",
       "12  0.216427   0.93902  0.203015        0.9439\n",
       "13  0.208698   0.94036  0.196107        0.9480\n",
       "14  0.201415   0.94264  0.190189        0.9489\n",
       "15  0.194538   0.94462  0.185116        0.9512\n",
       "16  0.188193   0.94642  0.180246        0.9527\n",
       "17  0.182208   0.94834  0.176056        0.9536\n",
       "18  0.176431   0.95000  0.170984        0.9549\n",
       "19  0.171171   0.95110  0.167114        0.9569\n",
       "20  0.166222   0.95244  0.161965        0.9575\n",
       "21  0.161376   0.95420  0.159494        0.9587\n",
       "22  0.156744   0.95526  0.156209        0.9585\n",
       "23  0.152522   0.95670  0.152179        0.9602\n",
       "24  0.148377   0.95770  0.149537        0.9602\n",
       "25  0.144361   0.95878  0.146094        0.9621\n",
       "26  0.140522   0.96022  0.143519        0.9617\n",
       "27  0.137130   0.96114  0.141524        0.9619\n",
       "28  0.133547   0.96212  0.138252        0.9622\n",
       "29  0.130155   0.96356  0.137114        0.9642\n",
       "30  0.127113   0.96430  0.133499        0.9640\n",
       "31  0.123854   0.96520  0.131669        0.9645\n",
       "32  0.121097   0.96630  0.129751        0.9654\n",
       "33  0.118215   0.96704  0.127277        0.9654\n",
       "34  0.115489   0.96772  0.125090        0.9674\n",
       "35  0.112773   0.96824  0.123971        0.9669\n",
       "36  0.110402   0.96914  0.122230        0.9680\n",
       "37  0.107958   0.96984  0.120988        0.9684\n",
       "38  0.105451   0.97036  0.119136        0.9688\n",
       "39  0.103215   0.97062  0.117664        0.9695\n",
       "40  0.100928   0.97186  0.115595        0.9694\n",
       "41  0.098850   0.97244  0.114805        0.9700\n",
       "42  0.096744   0.97306  0.113830        0.9705\n",
       "43  0.094582   0.97370  0.112315        0.9702\n",
       "44  0.092676   0.97474  0.111058        0.9707\n",
       "45  0.090782   0.97490  0.110012        0.9699\n",
       "46  0.089006   0.97530  0.108010        0.9714\n",
       "47  0.087155   0.97578  0.107557        0.9715\n",
       "48  0.085364   0.97628  0.106331        0.9705\n",
       "49  0.083905   0.97698  0.104786        0.9718"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08784119784832001, 0.9722999930381775]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_7740\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 247ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.2204752e-05, 8.7629402e-08, 1.8228240e-04, 1.1569110e-03,\n",
       "        2.8983422e-07, 1.1299928e-05, 1.3953932e-09, 9.9848986e-01,\n",
       "        5.3510070e-05, 9.3523791e-05]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1])\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_7740\\4029188365.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[1].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 968,    0,    1,    1,    1,    3,    1,    3,    1,    1],\n",
       "       [   0, 1122,    3,    1,    0,    1,    3,    1,    4,    0],\n",
       "       [   4,    1, 1003,    3,    2,    1,    3,    8,    7,    0],\n",
       "       [   0,    0,    4,  984,    0,    5,    0,    6,    8,    3],\n",
       "       [   2,    0,    4,    0,  949,    0,    3,    2,    2,   20],\n",
       "       [   6,    1,    1,    8,    1,  859,    7,    1,    6,    2],\n",
       "       [   9,    3,    1,    1,    5,    6,  925,    1,    7,    0],\n",
       "       [   0,    7,   10,    3,    0,    1,    0,  997,    1,    9],\n",
       "       [   4,    0,    4,    5,    4,    6,    2,    4,  943,    2],\n",
       "       [   5,    4,    1,   10,    8,    2,    0,    6,    0,  973]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, model.predict(X_test).argmax(axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.0655 - val_loss: 0.4970\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 4.7724 - val_loss: 1.7011\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.6861 - val_loss: 1.0420\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 15.5632 - val_loss: 0.6596\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5602 - val_loss: 0.5224\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4845 - val_loss: 0.4843\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4562 - val_loss: 0.4691\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4451 - val_loss: 0.4689\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4375 - val_loss: 0.4568\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4287 - val_loss: 0.4402\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4196 - val_loss: 0.4344\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4126 - val_loss: 0.4350\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4187 - val_loss: 0.4267\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4085 - val_loss: 0.4192\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4114 - val_loss: 0.4356\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4043 - val_loss: 0.4204\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3939 - val_loss: 0.4046\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3875 - val_loss: 0.4011\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3833 - val_loss: 0.3968\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3783 - val_loss: 0.3908\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301 (1.18 KB)\n",
      "Trainable params: 301 (1.18 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3964\n",
      "0.3964376151561737\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 126ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.6855011 ],\n",
       "       [1.3080385 ],\n",
       "       [0.9562042 ],\n",
       "       [0.63501203],\n",
       "       [1.938515  ]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3765\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3716\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3692\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3659\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3697\n",
      "Epoch 6/30\n",
      "327/363 [==========================>...] - ETA: 0s - loss: 0.3656"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7740\\3275254796.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcheckpoint_cb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"callback_model.keras\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(X_train,\n\u001b[0m\u001b[0;32m      3\u001b[0m                    \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                    callbacks = [checkpoint_cb])\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1794\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1795\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1797\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1798\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1799\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[0;32m   1800\u001b[0m                             \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1801\u001b[0m                             \u001b[0mepoch_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1407\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_step\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m         ):\n\u001b[0;32m   1409\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1411\u001b[1;33m             \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1412\u001b[0m             can_run_full_execution = (\n\u001b[0;32m   1413\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    691\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    838\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mbound_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbound_arguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1262\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    308\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"graph\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;31m# Make sure we get an input with handle data attached from resource\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_data\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   4185\u001b[0m         _ctx, \"Identity\", name, input)\n\u001b[0;32m   4186\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4188\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4189\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4190\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4191\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4192\u001b[0m       return identity_eager_fallback(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.keras\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3873 - val_loss: 0.3987\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.4013\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3718 - val_loss: 0.4034\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3679 - val_loss: 0.3910\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3749 - val_loss: 0.3916\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3650 - val_loss: 0.4258\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3669 - val_loss: 0.3825\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3774 - val_loss: 0.3781\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3603 - val_loss: 0.3906\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3600 - val_loss: 0.3747\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3631 - val_loss: 0.3738\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3581 - val_loss: 0.3757\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3544 - val_loss: 0.3695\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3520 - val_loss: 0.3664\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3509 - val_loss: 0.3668\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3512 - val_loss: 0.3637\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3472 - val_loss: 0.3606\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3456 - val_loss: 0.3601\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3459 - val_loss: 0.3575\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3427 - val_loss: 0.3593\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3465 - val_loss: 0.3605\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3414 - val_loss: 0.3556\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3388 - val_loss: 0.3544\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3379 - val_loss: 0.3515\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3366 - val_loss: 0.3551\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3456 - val_loss: 0.3577\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3365 - val_loss: 0.3534\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3346 - val_loss: 0.3525\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3374 - val_loss: 0.3539\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3324 - val_loss: 0.3497\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3307 - val_loss: 0.3425\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3291 - val_loss: 0.3422\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3280 - val_loss: 0.3449\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3272 - val_loss: 0.3425\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3255 - val_loss: 0.3424\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3253 - val_loss: 0.3386\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3240 - val_loss: 0.3490\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3238 - val_loss: 0.3375\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3236 - val_loss: 0.3415\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3234 - val_loss: 0.3381\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3222 - val_loss: 0.3362\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3219 - val_loss: 0.3377\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3208 - val_loss: 0.3376\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3205 - val_loss: 0.3379\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3196 - val_loss: 0.3381\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3194 - val_loss: 0.3359\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3197 - val_loss: 0.3365\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3184 - val_loss: 0.3353\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3178 - val_loss: 0.3336\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3181 - val_loss: 0.3389\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb, checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "90139cb9a825bf3d63f6f6704e828dbd1ff7edbd4d0c6e906a71235d6efc74af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
